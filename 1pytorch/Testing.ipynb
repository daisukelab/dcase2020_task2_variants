{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "sys.path.append('..')\n",
    "import common as com\n",
    "\n",
    "param = com.yaml_load('config.yaml')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = com.select_dirs(param=param, mode='development')\n",
    "target_dir = dirs[0]\n",
    "files = com.file_list_generator(target_dir)\n",
    "v = com.list_to_vector_array(files[:2])\n",
    "plt.plot(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor1d(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: (dim,) feature array.\n",
    "    \"\"\"\n",
    "    def __call__(self, array):\n",
    "        assert len(array.shape) == 1\n",
    "        return torch.Tensor(array).unsqueeze(0).to(device)\n",
    "    def __repr__(self):\n",
    "        return 'to_tensor_1d'\n",
    "\n",
    "class MelsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files, n_mels, frames, n_fft, hop_length, power, transform):\n",
    "        self.transform = transform\n",
    "        self.files = files\n",
    "        self.n_mels, self.frames, self.n_fft = n_mels, frames, n_fft\n",
    "        self.hop_length, self.power = hop_length, power\n",
    "        self.X = com.list_to_vector_array(files,\n",
    "                         n_mels=self.n_mels,\n",
    "                         frames=self.frames,\n",
    "                         n_fft=self.n_fft,\n",
    "                         hop_length=self.hop_length,\n",
    "                         power=self.power)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        x = self.transform(x)\n",
    "        return x, x\n",
    "\n",
    "# ds = MelsDataset(files[:10],\n",
    "#                  n_mels=param[\"feature\"][\"n_mels\"],\n",
    "#                  frames=param[\"feature\"][\"frames\"],\n",
    "#                  n_fft=param[\"feature\"][\"n_fft\"],\n",
    "#                  hop_length=param[\"feature\"][\"hop_length\"],\n",
    "#                  power=param[\"feature\"][\"power\"],\n",
    "#                  transform=ToTensor1d())\n",
    "# ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class LinUnit(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(in_dim, out_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.bn(self.lin(x.view(x.size(0), -1))))\n",
    "\n",
    "\n",
    "class Task2Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        # not the best model...\n",
    "        self.unit1 = LinUnit(640, 128)\n",
    "        self.unit2 = LinUnit(128, 128)\n",
    "        self.unit3 = LinUnit(128, 128)\n",
    "        self.unit4 = LinUnit(128, 128)\n",
    "        self.unit5 = LinUnit(128, 8)\n",
    "        self.unit6 = LinUnit(8, 128)\n",
    "        self.unit7 = LinUnit(128, 128)\n",
    "        self.unit8 = LinUnit(128, 128)\n",
    "        self.unit9 = LinUnit(128, 128)\n",
    "        self.output = torch.nn.Linear(128, 640)\n",
    "        self.mseloss = torch.nn.MSELoss()\n",
    "        self.hparams = hparams\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.unit1(x.view(x.size(0), -1))\n",
    "        x = self.unit2(x)\n",
    "        x = self.unit3(x)\n",
    "        x = self.unit4(x)\n",
    "        x = self.unit5(x)\n",
    "        x = self.unit6(x)\n",
    "        x = self.unit7(x)\n",
    "        x = self.unit8(x)\n",
    "        x = self.unit9(x)\n",
    "        return self.output(x)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.mseloss(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return {'val_loss': self.mseloss(y_hat, y)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "#     def test_step(self, batch, batch_nb):\n",
    "#         # OPTIONAL\n",
    "#         x, y = batch\n",
    "#         y_hat = self.forward(x)\n",
    "#         return {'test_loss': self.mseloss(y_hat, y)}\n",
    "\n",
    "#     def test_epoch_end(self, outputs):\n",
    "#         # OPTIONAL\n",
    "#         avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "#         logs = {'test_loss': avg_loss}\n",
    "#         return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr,\n",
    "                                betas=(self.hparams.b1, self.hparams.b2))\n",
    "\n",
    "    def get_ds(self, files):\n",
    "        return MelsDataset(files,\n",
    "                           n_mels=self.hparams.n_mels,\n",
    "                           frames=self.hparams.frames,\n",
    "                           n_fft=self.hparams.n_fft,\n",
    "                           hop_length=self.hparams.hop_length,\n",
    "                           power=self.hparams.power,\n",
    "                           transform=ToTensor1d())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(self.get_ds(files), batch_size=self.hparams.batch_size,\n",
    "                          shuffle=self.hparams.shuffle)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(self.get_ds(files[:512]), batch_size=self.hparams.batch_size, shuffle=False)\n",
    "\n",
    "#     def test_dataloader(self):\n",
    "#         # OPTIONAL\n",
    "#         return DataLoader(self.get_ds(files[:512]), batch_size=self.hparams.batch_size)\n",
    "\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'epochs': param['fit']['epochs'],\n",
    "    'batch_size': param['fit']['batch_size'],\n",
    "    'lr': 0.0002,\n",
    "    'b1': 0.5,\n",
    "    'b2': 0.999,\n",
    "    'shuffle': param['fit']['shuffle'],\n",
    "    'n_mels': param[\"feature\"][\"n_mels\"],\n",
    "    'frames': param[\"feature\"][\"frames\"],\n",
    "    'n_fft': param[\"feature\"][\"n_fft\"],\n",
    "    'hop_length': param[\"feature\"][\"hop_length\"],\n",
    "    'power': param[\"feature\"][\"power\"],\n",
    "}\n",
    "hparams = Namespace(**args)\n",
    "\n",
    "task2_model = Task2Model(hparams)\n",
    "print(f'Start training with {torch.cuda.device_count()} GPU(s).')\n",
    "trainer = pl.Trainer(max_epochs=hparams.epochs, gpus=torch.cuda.device_count())\n",
    "trainer.fit(task2_model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 2\n",
    "frames = 5\n",
    "dims = frames * n_mels\n",
    "vector_array_size = 50\n",
    "tmp = np.array(list(range(vector_array_size + frames - 1)))\n",
    "log_mel_spectrogram = np.c_[tmp, tmp+0.1].T\n",
    "\n",
    "vector_array = np.zeros((vector_array_size, dims))\n",
    "print(log_mel_spectrogram.shape, vector_array.shape)\n",
    "for t in range(frames):\n",
    "    vector_array[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + vector_array_size].T\n",
    "\n",
    "print(vector_array)\n",
    "#print(log_mel_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task2",
   "language": "python",
   "name": "task2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
